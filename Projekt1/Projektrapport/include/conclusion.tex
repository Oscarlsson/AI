\chapter{Conclusions}
During the project we have learned that classification algorithms might be easy to implement but small changes in feature selection yields a big change in classification performance. It is hard to know in advance what features will work good on a given data, without executing heavy tests and measuring. During the project we performed lots of tests, some of which have taken long nights to run. 
\\\\
We have both studied the theoretical similarity between Support Vector Machines and Perceptron and practically shown the similarity (Figure \ref{fig:featuresize}).
\\\\
K-nearest neighbour did not perform as good as the other algorithms on this particular dataset. 
\section{Future work}
The bigram-feature gave bad results and we did not have time to investigate this further but one could continue where we stopped and try to achieve better classifications using bigram. \\\\
Boosting is a meta-algorithm in supervised learning which takes a set of weak learners and creates a single large learner. (ref till http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf) It would have been interesting to e.g. implement AdaBoost and messure the performance gain. \\\\
K-nearest neighbor gave worse classification than the other algorithms and it would have been interesting to investigate if some parameters would turn the situation around and make KNN better. We did not have time to investigate if some feature selection would make KNN equivalent to the others.
\\\\
Another interesting task would have been to apply unsupervised learning methods on the datasets to see how well the extracted features and clusterings correspond to the data labels, for instance by experimenting with the EM-algorithm and the LDA-algorithm.
%Modules a future continuation may have
%\\\\
%* annat dataset\\
%* fler ord\\
%* kombinera algoritmer\\
%* boosting\\
