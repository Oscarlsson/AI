\chapter{Conclusions}
During the project we have learned that classification algorithms might be easy to implement but small changes in feature selection yields a big change in classification performance. It's hard to know in advance what features will work good on a give data, without executing heavy tests and measuring. During the project we have been performing lots of tests, some of which have taken nights to perform. 
\\\\
We have both studied the theoretical similarity between Support Vector Machines and Perceptron and practically shown the similarity (Figure \ref{fig:featuresize}).
\\\\
K-nearest neighbour didn't perform as good as the other algorithms, on this particular dataset. We assume that our performance of KNN is not as good as the theoretical best. ??  
\section{Future work}
It would have been interesting to study the correlation with another dataset than the Amazon.  \\\\
The bigram-feature gave bad results and we didn't have time to investigate this further but one could continue where we stopped and try to achieve better classification using bigram. \\\\
Boosting is a meta-algorithm in supervised learning which takes a set of weak learners and creates a single large learner. (ref till http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf) It would have been interesting to e.g implement AdaBoost and messure the performance gain. \\\\
K-nearest neighbor gave worse classification than the other algorithms and it would have been interesting to investigate if some parameters would turn the situation around and make KNN better. We didn't have time to investigate if some feature selection would make KNN equivalent to the others.
%Modules a future continuation may have
%\\\\
%* annat dataset\\
%* fler ord\\
%* kombinera algoritmer\\
%* boosting\\
